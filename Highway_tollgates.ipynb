{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the path according to the location of files\n",
    "test_volume = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/testing_phase1/test1_20min_avg_volume.csv\", names=[\"tollgate_id\",\"time_window\",\"direction\",\"volume\"])\n",
    "test_travel_time = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/testing_phase1/test1_20min_avg_travel_time.csv\", names = [\"intersection_id\",\"tollgate_id\",\"time_window\",\"avg_travel_time\"])\n",
    "training_volume = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/training/training_20min_avg_volume.csv\", names=[\"tollgate_id\",\"time_window\",\"direction\",\"volume\"])\n",
    "training_travel_time = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/training/training_20min_avg_travel_time.csv\", names = [\"intersection_id\",\"tollgate_id\",\"time_window\",\"avg_travel_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate a general vector\n",
    "def generate_vector(data_frame, data_type):\n",
    "    P_expanded = data_frame['time_window'].apply(lambda x: pd.Series(x.split(',')))\n",
    "    P_expanded[1] = P_expanded[1].apply(str).apply(lambda x : pd.Series(x.rstrip(')')))\n",
    "    P_expanded[0] = P_expanded[0].apply(str).apply(lambda x : pd.Series(x.lstrip('[')))\n",
    "    data_frame = data_frame.join(P_expanded)\n",
    "    del data_frame[\"time_window\"]\n",
    "    if (data_type == \"volume\"):\n",
    "        data_frame = data_frame[[\"tollgate_id\",0,1,\"direction\", \"volume\"]] \n",
    "    else:\n",
    "        data_frame = data_frame[[\"intersection_id\",\"tollgate_id\",0,1,\"avg_travel_time\"]]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_volume = generate_vector(training_volume, \"volume\")\n",
    "test_travel_time = generate_vector(test_travel_time, \"travel_time\")\n",
    "test_volume = generate_vector(test_volume, \"volume\")\n",
    "training_travel_time = generate_vector(training_travel_time, \"travel_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the path according to the location of files\n",
    "training_weather_data = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/testing_phase1/weather (table 7)_test1.csv\", names=[\"date\",\"hour\",\"pressure\",\"sea_pressure\",\"wind_direction\",\"wind_speed\",\"temperature\",\"rel_humidity\",\"precipitation\"])\n",
    "testing_weather_data = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/training/weather (table 7)_training.csv\", names=[\"date\",\"hour\",\"pressure\",\"sea_pressure\",\"wind_direction\",\"wind_speed\",\"temperature\",\"rel_humidity\",\"precipitation\"])\n",
    "routes = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/training/routes (table 4).csv\")\n",
    "links = pd.read_csv(\"C:/Users/Shruti1481/PycharmProjects/HighwayTrafficPrediction/DATA/dataSets/dataSets/training/links (table 3).csv\")\n",
    "links = links.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process links file\n",
    "links[[\"in_top\",\"out_top\"]] = links[[\"in_top\",\"out_top\"]].values.astype(str)\n",
    "in_top = links['in_top'].apply(lambda x: pd.Series(x.split(',')))\n",
    "out_top = links['out_top'].apply(lambda x: pd.Series(x.split(',')))\n",
    "links[[\"in_top_0\",\"in_top_1\"]] = in_top\n",
    "links[[\"out_top_0\",\"out_top_1\"]] = out_top\n",
    "del links['in_top']\n",
    "del links['out_top']\n",
    "links = links [['link_id', 'length', 'width', 'lanes', 'in_top_0', 'in_top_1', 'out_top_0', 'out_top_1',\n",
    "       'lane_width']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_volume_vector(volume_data, weather_data):\n",
    "    weather_data[\"hour\"] = weather_data[\"hour\"].apply(str)\n",
    "    weather_data[\"hour\"] = weather_data[\"hour\"] + \":00\"\n",
    "    weather_data[0] = weather_data['date'] + ' ' + weather_data['hour']\n",
    "    del weather_data[\"date\"]\n",
    "    del weather_data[\"hour\"]\n",
    "    weather_data[0] = pd.to_datetime(weather_data[0])\n",
    "    volume_data[0] = pd.to_datetime(volume_data[0]) \n",
    "    volume_vector = volume_data.join(weather_data.set_index(0).reindex(volume_data.set_index(0).index, method='nearest').reset_index(), how='right',  lsuffix='_start', rsuffix='_weather')\n",
    "    del volume_vector[\"0_weather\"]\n",
    "    new_columns = volume_vector.columns.values\n",
    "    new_columns[1] = 0\n",
    "    volume_vector.columns = new_columns\n",
    "    volume_vector = volume_vector[['tollgate_id', 0, 1, 'direction', 'pressure',\n",
    "       'sea_pressure', 'wind_direction', 'wind_speed', 'temperature',\n",
    "       'rel_humidity', 'precipitation', 'volume']]\n",
    "    return volume_vector    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_volume_vector(volume_vector):\n",
    "    #to float direction\n",
    "    volume_vector[\"direction\"] = volume_vector[\"direction\"].values.astype(float) \n",
    "\n",
    "    #standardize other columns\n",
    "    x = volume_vector[[\"pressure\", \"sea_pressure\", \"wind_direction\",\"temperature\", \"rel_humidity\"]].values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.T)\n",
    "    volume_vector_normalized = pd.DataFrame(x_scaled.T)\n",
    "\n",
    "    volume_vector[\"pressure\"] = volume_vector_normalized[0]\n",
    "    volume_vector[\"sea_pressure\"] = volume_vector_normalized[1]\n",
    "    volume_vector[\"wind_direction\"] = volume_vector_normalized[2]\n",
    "    volume_vector[\"rel_humidity\"] = volume_vector_normalized[3]\n",
    "    \n",
    "    del volume_vector[1]\n",
    "    volume_vector = volume_vector.assign(time_window=20)\n",
    "    \n",
    "    #preprocess time\n",
    "    x = volume_vector[0].values.astype(float)\n",
    "    x = x.reshape((len(x), 1))\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0, 2))\n",
    "    y = scaler.fit_transform(x)\n",
    "    volume_vector[0] = pd.DataFrame(y)\n",
    "    volume_vector = volume_vector[['tollgate_id', 0, 'time_window', 'direction', 'pressure', 'sea_pressure',\n",
    "       'wind_direction', 'wind_speed', 'temperature', 'rel_humidity',\n",
    "       'precipitation', 'volume']]\n",
    "    return volume_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the unprocessed vectors\n",
    "train_volume_vector = get_volume_vector(training_volume,training_weather_data)\n",
    "test_volume_vector = get_volume_vector(test_volume,testing_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standardize the vector data\n",
    "train_volume_vector = process_volume_vector(train_volume_vector)\n",
    "test_volume_vector = process_volume_vector(test_volume_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_links(vector, vector_expanded, name, number):\n",
    "    vector[name] = vector_expanded[number]\n",
    "    vector[name] = pd.to_numeric(vector[name])\n",
    "    vector = pd.merge(vector, links, how='inner', left_on=[name], right_on=['link_id'])\n",
    "    return vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_travel_time_vector(travel_vector, weather_data):\n",
    "    travel_vector[0] = pd.to_datetime(travel_vector[0]) \n",
    "    travel_vector['avg_travel_time'] = pd.to_numeric(travel_vector['avg_travel_time'])\n",
    "    travel_vector_joined = travel_vector.join(weather_data.set_index(0).reindex(travel_vector.set_index(0).index, method='nearest').reset_index(), how='right',  lsuffix='_start', rsuffix='_weather')\n",
    "    travel_vector_joined = pd.merge(travel_vector_joined, routes, how='inner', on=['intersection_id', 'tollgate_id'])\n",
    "    travel_vector_joined_expanded = travel_vector_joined['link_seq'].apply(lambda x: pd.Series(x.split(',')))\n",
    "   \n",
    "    links['link_id'] =  pd.to_numeric(links['link_id']) \n",
    "\n",
    "    travel_vector_joined = add_links(travel_vector_joined, travel_vector_joined_expanded, 'first_link_id', 0 )\n",
    "    travel_vector_joined = add_links(travel_vector_joined, travel_vector_joined_expanded, 'second_link_id', 1 )\n",
    "    travel_vector_joined = add_links(travel_vector_joined, travel_vector_joined_expanded, 'third_link_id', 2 )\n",
    "    travel_vector_joined = add_links(travel_vector_joined, travel_vector_joined_expanded, 'fourth_link_id', 3 )\n",
    "    travel_vector_joined = add_links(travel_vector_joined, travel_vector_joined_expanded, 'fifth_link_id', 4 )\n",
    "    \n",
    "    travel_vector_joined = travel_vector_joined.assign(time_window = 20)\n",
    "    del travel_vector_joined['0_weather']\n",
    "    del travel_vector_joined['link_seq']\n",
    "    del travel_vector_joined['link_id_x']\n",
    "    del travel_vector_joined['link_id_y']\n",
    "    del travel_vector_joined['link_id']\n",
    "    del travel_vector_joined[1]\n",
    "    \n",
    "    travel_vector_joined = travel_vector_joined[['intersection_id', 'tollgate_id', '0_start', 'time_window',\n",
    "       'pressure', 'sea_pressure', 'wind_direction', 'wind_speed',\n",
    "       'temperature', 'rel_humidity', 'precipitation', 'first_link_id',\n",
    "       'length_x', 'width_x', 'lanes_x', 'in_top_0_x', 'in_top_1_x',\n",
    "       'out_top_0_x', 'out_top_1_x', 'lane_width_x', 'second_link_id',\n",
    "       'length_y', 'width_y', 'lanes_y', 'in_top_0_y', 'in_top_1_y',\n",
    "       'out_top_0_y', 'out_top_1_y', 'lane_width_y', 'third_link_id',\n",
    "       'length_x', 'width_x', 'lanes_x', 'in_top_0_x', 'in_top_1_x',\n",
    "       'out_top_0_x', 'out_top_1_x', 'lane_width_x', 'fourth_link_id',\n",
    "       'length_y', 'width_y', 'lanes_y', 'in_top_0_y', 'in_top_1_y',\n",
    "       'out_top_0_y', 'out_top_1_y', 'lane_width_y', 'fifth_link_id',\n",
    "       'length', 'width', 'lanes', 'in_top_0', 'in_top_1', 'out_top_0',\n",
    "       'out_top_1', 'lane_width', 'avg_travel_time']]\n",
    "    \n",
    "    \n",
    "    return travel_vector_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_travel_time = get_travel_time_vector(training_travel_time,training_weather_data)\n",
    "test_travel_time = get_travel_time_vector(test_travel_time,testing_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_travel_data(travel_vector):\n",
    "    le = LabelEncoder()\n",
    "    df = pd.DataFrame(travel_vector['intersection_id'], columns=['intersection_id'])\n",
    "    encoded_series = df[df.columns[:]].apply(le.fit_transform)\n",
    "    travel_vector['intersection_id'] = encoded_series\n",
    "    \n",
    "    #standardize other columns\n",
    "    x = travel_vector[[\"pressure\", \"sea_pressure\", \"wind_direction\",\"temperature\", \"rel_humidity\"]].values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.T)\n",
    "    travel_vector_normalized = pd.DataFrame(x_scaled.T)\n",
    "\n",
    "    travel_vector[\"pressure\"] = travel_vector_normalized[0]\n",
    "    travel_vector[\"sea_pressure\"] = travel_vector_normalized[1]\n",
    "    travel_vector[\"wind_direction\"] = travel_vector_normalized[2]\n",
    "    travel_vector[\"rel_humidity\"] = travel_vector_normalized[3]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #preprocess time\n",
    "    x = travel_vector['0_start'].values.astype(float)\n",
    "    x = x.reshape((len(x), 1))\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0, 2))\n",
    "    y = scaler.fit_transform(x)\n",
    "    travel_vector['0_start'] = pd.DataFrame(y)\n",
    "    \n",
    "    travel_vector = travel_vector.fillna(0)\n",
    "   \n",
    "    return travel_vector\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_travel_vector_processed = process_travel_data(train_travel_time)\n",
    "testing_travel_vector_processed = process_travel_data(test_travel_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding the MAPE for travel time\n",
    "def mean_absolute_percentage_error_travel(travel_vector, actual_travel_time, predicted_travel_time):\n",
    "    travel_time = {}\n",
    "    for i in range(len(travel_vector)):\n",
    "        results = abs((actual_travel_time[i] - predicted_travel_time[i]) / actual_travel_time[i])  \n",
    "        key = str(int(travel_vector['intersection_id'][i])) + \"-\" + str(int(travel_vector['tollgate_id'][i]))\n",
    "        if key not in travel_time:\n",
    "            travel_time[key] = {}\n",
    "        time_window = str(travel_vector['0_start'][i]) \n",
    "        \n",
    "        if time_window not in travel_time[key]:\n",
    "            travel_time[key][time_window] = results\n",
    "        else:\n",
    "            travel_time[key][time_window] += results\n",
    "\n",
    "    tollgate_number = len(travel_time)\n",
    "    mape = 0.0\n",
    "    for detail in travel_time:\n",
    "        tollgate_number_content = len(travel_time[detail])\n",
    "        total = 0.0\n",
    "        for time in travel_time[detail]:\n",
    "            total += travel_time[detail][time]\n",
    "        mape += (total) / tollgate_number_content\n",
    "    mape = mape / tollgate_number\n",
    "    \n",
    "\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error_volume(volume_vector, actual_volume, predicted_volume):\n",
    "    volume = {}\n",
    "    for i in range(len(volume_vector)):\n",
    "        result = abs((actual_volume[i] - predicted_volume[i]) / actual_volume[i]) # resultult of current instance\n",
    "        key = str(int(volume_vector['tollgate_id'][i])) + \"-\" + str(int(volume_vector['direction'][i]))\n",
    "        if key not in volume:\n",
    "            volume[key] = {}\n",
    "        time_window = str(volume_vector['tollgate_id'][i]) + \"-\" + str(volume_vector[0][i])\n",
    "        if time_window not in volume[key]:\n",
    "            # Current Timegate doesn't exist\n",
    "            volume[key][time_window] = result\n",
    "        else:\n",
    "            # Current Timegate exists\n",
    "            volume[key][time_window] += result\n",
    "\n",
    "    \n",
    "    mape = 0.0\n",
    "    tollgate_number = len(volume)\n",
    "    for detail in volume:\n",
    "        tollgate_number_content = len(volume[detail])\n",
    "        tempSum = 0.0\n",
    "        for time in volume[detail]:\n",
    "            tempSum += volume[detail][time]\n",
    "        mape += (tempSum)/tollgate_number_content\n",
    "    mape = mape / tollgate_number\n",
    "    return mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_volume_x = train_volume_vector.loc[:,train_volume_vector.columns != 'volume']\n",
    "train_volume_y = train_volume_vector['volume'] \n",
    "test_volume_x = test_volume_vector.loc[:,test_volume_vector.columns != 'volume']\n",
    "test_volume_y = test_volume_vector['volume'] \n",
    "train_travel_x = training_travel_vector_processed.loc[:,training_travel_vector_processed.columns != 'avg_travel_time']\n",
    "train_travel_y = training_travel_vector_processed['avg_travel_time'] \n",
    "test_travel_x = testing_travel_vector_processed.loc[:,testing_travel_vector_processed.columns != 'avg_travel_time']\n",
    "test_travel_y = testing_travel_vector_processed['avg_travel_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Decision Tree Regressor###\n",
    "def decisionTreeRegressor_volume():\n",
    "    volume_regression = DecisionTreeRegressor()\n",
    "  \n",
    "    #train the model to predict volume and calculate errors\n",
    "    volume_regression.fit(train_volume_x, train_volume_y)\n",
    "    predicted_volume = volume_regression.predict(test_volume_x)\n",
    "    volume_mean_square_error = mean_squared_error(predicted_volume,test_volume_y)\n",
    "    volume_absolute_error = mean_absolute_error(predicted_volume,test_volume_y)\n",
    "    error = mean_absolute_percentage_error_volume(test_volume_x,test_volume_y ,predicted_volume)\n",
    "    return volume_mean_square_error,volume_absolute_error, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decisionTreeRegressor_travel_time():\n",
    "    travel_time_regression = DecisionTreeRegressor()\n",
    "    \n",
    "    #train the model to predict travel time and calculate errors\n",
    "    travel_time_regression.fit(train_travel_x, train_travel_y)\n",
    "    predicted_travel_time = travel_time_regression.predict(test_travel_x)\n",
    "    time_mse = mean_squared_error(predicted_travel_time,test_travel_y)\n",
    "    time_mae = mean_absolute_error(predicted_travel_time,test_travel_y)\n",
    "    time_mape = mean_absolute_percentage_error_travel(test_travel_x,test_travel_y ,predicted_travel_time)\n",
    "    return time_mse,time_mae,time_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_mse_DT,volume_mae_DT,volume_mape_DT = decisionTreeRegressor_volume()\n",
    "time_mse_DT,time_mae_DT,time_mape_DT = decisionTreeRegressor_travel_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume: 3361.97142857 46.8142857143 0.914565112321\n",
      "travel: 5641.92102634 42.1175446429 0.331464636469\n"
     ]
    }
   ],
   "source": [
    "print('volume:',volume_mse_DT,volume_mae_DT,volume_mape_DT)\n",
    "print('travel:',time_mse_DT,time_mae_DT,time_mape_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###SVR Volume####\n",
    "def SVR_volume():\n",
    "    svr_clf = SVR(C=1.0, epsilon=0.2)\n",
    "    svr_clf.fit(train_volume_x,train_volume_y)\n",
    "    svr_predicted_volume = svr_clf.predict(test_volume_x)\n",
    "    volume_mean_square_error_svr = mean_squared_error(svr_predicted_volume,test_volume_y)\n",
    "    volume_absolute_error_svr = mean_absolute_error(svr_predicted_volume,test_volume_y)\n",
    "    error_svr = mean_absolute_percentage_error_volume(test_volume_x,test_volume_y ,svr_predicted_volume)\n",
    "    return volume_mean_square_error_svr,volume_absolute_error_svr, error_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###SVR Travel time####\n",
    "def SVR_travel_time():\n",
    "    svr_clf = SVR(C=1.0, epsilon=0.2)\n",
    "    svr_clf.fit(train_travel_x, train_travel_y)\n",
    "    svr_predicted_travel_time = svr_clf.predict(test_travel_x)\n",
    "    travel_time_mse_svr = mean_squared_error(svr_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mae_svr = mean_absolute_error(svr_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mape_svr = mean_absolute_percentage_error_travel(test_travel_x,test_travel_y ,svr_predicted_travel_time)\n",
    "    return travel_time_mse_svr,travel_time_mae_svr, travel_time_mape_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_mse_SVR,volume_mae_SVR,volume_mape_SVR = SVR_volume()\n",
    "time_mse_SVR,time_mae_SVR,time_mape_SVR = SVR_travel_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume: 1661.8157026 32.9731943046 0.5586230289\n",
      "travel: 2099.33590758 26.5254086869 0.201875255101\n"
     ]
    }
   ],
   "source": [
    "print('volume:', volume_mse_SVR,volume_mae_SVR,volume_mape_SVR)\n",
    "print('travel:', time_mse_SVR,time_mae_SVR,time_mape_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bayesian Ridge volume prediction ##\n",
    "def BayesianRidge_volume():\n",
    "    bay_clf = linear_model.BayesianRidge()\n",
    "    bay_clf.fit(train_volume_x,train_volume_y)\n",
    "    bay_predicted_volume = bay_clf.predict(test_volume_x)\n",
    "    bay_clf = linear_model.BayesianRidge()\n",
    "    bay_clf.fit(train_volume_x,train_volume_y)\n",
    "    bay_predicted_volume = bay_clf.predict(test_volume_x)\n",
    "    volume_mse_bay = mean_squared_error(bay_predicted_volume,test_volume_y)\n",
    "    volume_mae_bay = mean_absolute_error(bay_predicted_volume,test_volume_y)\n",
    "    volume_mape_bay = mean_absolute_percentage_error_volume(test_volume_x,test_volume_y ,bay_predicted_volume)\n",
    "    return volume_mse_bay,volume_mae_bay, volume_mape_bay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Bayesian Ridge Travel time####\n",
    "def BayesianRidge_travel_time():\n",
    "    bay_clf = linear_model.BayesianRidge()\n",
    "    bay_clf.fit(train_travel_x, train_travel_y)\n",
    "    bay_predicted_travel_time = bay_clf.predict(test_travel_x)\n",
    "    travel_time_mse_bay = mean_squared_error(bay_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mae_bay = mean_absolute_error(bay_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mape_bay = mean_absolute_percentage_error_travel(test_travel_x,test_travel_y ,bay_predicted_travel_time)\n",
    "    return travel_time_mse_bay,travel_time_mae_bay, travel_time_mape_bay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "volume_mse_BR,volume_mae_BR,volume_mape_BR = BayesianRidge_volume()\n",
    "time_mse_BR,time_mae_BR,time_mape_BR = BayesianRidge_travel_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume: 1465.3170762 31.2057339491 0.615976677619\n",
      "travel: 1781.26996322 25.3077006077 0.210225140542\n"
     ]
    }
   ],
   "source": [
    "print('volume:', volume_mse_BR,volume_mae_BR,volume_mape_BR)\n",
    "print('travel:', time_mse_BR,time_mae_BR,time_mape_BR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## K Nearest Neighbours Regression volume prediction ##\n",
    "def KNN_volume():\n",
    "    knn_clf = KNeighborsRegressor(n_neighbors =2500)\n",
    "    knn_clf.fit(train_volume_x,train_volume_y)\n",
    "    knn_predicted_volume = knn_clf.predict(test_volume_x)\n",
    "    volume_mse_knn = mean_squared_error(knn_predicted_volume,test_volume_y)\n",
    "    volume_mae_knn = mean_absolute_error(knn_predicted_volume,test_volume_y)\n",
    "    volume_mape_knn = mean_absolute_percentage_error_volume(test_volume_x,test_volume_y ,knn_predicted_volume)\n",
    "    return volume_mse_knn,volume_mae_knn, volume_mape_knn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###K Nearest Neighbours Regression Travel time####\n",
    "def KNN_travel_time():\n",
    "    knn_clf = KNeighborsRegressor(n_neighbors =2500)\n",
    "    knn_clf.fit(train_travel_x, train_travel_y)\n",
    "    knn_predicted_travel_time = knn_clf.predict(test_travel_x)\n",
    "    travel_time_mse_knn = mean_squared_error(knn_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mae_knn = mean_absolute_error(knn_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mape_knn = mean_absolute_percentage_error_travel(test_travel_x,test_travel_y ,knn_predicted_travel_time)\n",
    "    return travel_time_mse_knn,travel_time_mae_knn, travel_time_mape_knn \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_mse_KNN,volume_mae_KNN,volume_mape_KNN = KNN_volume()\n",
    "time_mse_KNN,time_mae_KNN,time_mape_KNN = KNN_travel_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume: 1418.96856347 31.4203228571 0.632595341123\n",
      "travel: 2204.57691387 28.4908805893 0.229760059494\n"
     ]
    }
   ],
   "source": [
    "print('volume:', volume_mse_KNN,volume_mae_KNN,volume_mape_KNN)\n",
    "print('travel:', time_mse_KNN,time_mae_KNN,time_mape_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Random Forest Regression volume prediction ##\n",
    "def RF_volume():\n",
    "    rf_clf = RandomForestRegressor(max_depth=3, random_state=1)\n",
    "    rf_clf.fit(train_volume_x,train_volume_y)\n",
    "    rf_predicted_volume = rf_clf.predict(test_volume_x)\n",
    "    volume_mse_rf = mean_squared_error(rf_predicted_volume,test_volume_y)\n",
    "    volume_mae_rf = mean_absolute_error(rf_predicted_volume,test_volume_y)\n",
    "    volume_mape_rf = mean_absolute_percentage_error_volume(test_volume_x,test_volume_y ,rf_predicted_volume)\n",
    "    return volume_mse_rf,volume_mae_rf, volume_mape_rf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###RandomForest Travel time####\n",
    "def RF_travel_time():\n",
    "    rf_clf = RandomForestRegressor(max_depth=3, random_state=1)\n",
    "    rf_clf.fit(train_travel_x, train_travel_y)\n",
    "    rf_predicted_travel_time = rf_clf.predict(test_travel_x)\n",
    "    travel_time_mse_rf = mean_squared_error(rf_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mae_rf = mean_absolute_error(rf_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mape_rf = mean_absolute_percentage_error_travel(test_travel_x,test_travel_y ,rf_predicted_travel_time)\n",
    "    return travel_time_mse_rf,travel_time_mae_rf, travel_time_mape_rf \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_mse_RF,volume_mae_RF,volume_mape_RF = RF_volume()\n",
    "time_mse_RF,time_mae_RF,time_mape_RF = RF_travel_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume: 1413.57807453 31.1882618011 0.597842390574\n",
      "travel: 1845.66189727 25.8834434225 0.211492883615\n"
     ]
    }
   ],
   "source": [
    "print('volume:', volume_mse_RF,volume_mae_RF,volume_mape_RF)\n",
    "print('travel:', time_mse_RF,time_mae_RF,time_mape_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bagging Regressor volume prediction ##\n",
    "def Bagging_volume():\n",
    "    bg_clf = BaggingRegressor(base_estimator=SVR(C=1.0, epsilon=0.2),\n",
    "                           n_estimators=50,\n",
    "                           bootstrap=True,\n",
    "                           oob_score=True)\n",
    "    bg_clf.fit(train_volume_x,train_volume_y)\n",
    "    bg_predicted_volume = bg_clf.predict(test_volume_x)\n",
    "    volume_mse_bg = mean_squared_error(bg_predicted_volume,test_volume_y)\n",
    "    volume_mae_bg = mean_absolute_error(bg_predicted_volume,test_volume_y)\n",
    "    volume_mape_bg = mean_absolute_percentage_error_volume(test_volume_x,test_volume_y ,bg_predicted_volume)\n",
    "   \n",
    "    return volume_mse_bg,volume_mae_bg, volume_mape_bg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Bagging Regressor Travel time####\n",
    "def Bagging_travel_time():\n",
    "    bg_clf = BaggingRegressor(base_estimator=SVR(C=1.0, epsilon=0.2),\n",
    "                           n_estimators=50,\n",
    "                           bootstrap=True,\n",
    "                           oob_score=True)\n",
    "    bg_clf.fit(train_travel_x, train_travel_y)\n",
    "    bg_predicted_travel_time = bg_clf.predict(test_travel_x)\n",
    "    travel_time_mse_bg = mean_squared_error(bg_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mae_bg = mean_absolute_error(bg_predicted_travel_time,test_travel_y)\n",
    "    travel_time_mape_bg = mean_absolute_percentage_error_travel(test_travel_x,test_travel_y ,bg_predicted_travel_time)\n",
    "    return travel_time_mse_bg,travel_time_mae_bg, travel_time_mape_bg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_mse_bag,volume_mae_bag,volume_mape_bag = Bagging_volume()\n",
    "time_mse_bag,time_mae_bag,time_mape_bag = Bagging_travel_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('volume:', volume_mse_bag,volume_mae_bag,volume_mape_bag)\n",
    "print('travel:', time_mse_bag,time_mae_bag,time_mape_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_volume = []\n",
    "results_volume.append(volume_mape_DT)\n",
    "results_volume.append(volume_mape_RF)\n",
    "results_volume.append(volume_mape_BR)\n",
    "results_volume.append(volume_mape_SVR)\n",
    "results_volume.append(volume_mape_KNN)\n",
    "results_volume.append(volume_mape_bag)\n",
    "results_travel = []\n",
    "results_travel.append(time_mape_DT)\n",
    "results_travel.append(time_mape_RF)\n",
    "results_travel.append(time_mape_BR)\n",
    "results_travel.append(time_mape_SVR)\n",
    "results_travel.append(time_mape_KNN)\n",
    "results_travel.append(time_mape_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##plot for volume for 20 mins\n",
    "\n",
    "n_groups = 1\n",
    "\n",
    " \n",
    "# create plot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rcParams['figure.figsize'] = 12,10\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.2\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, results_volume[1], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Random Forest')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, results_volume[2], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='Bayesian Regression ')\n",
    "\n",
    "rects3 = plt.bar(index + 2 *bar_width, results_volume[3], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='SVR')\n",
    "\n",
    "rects5 = plt.bar(index + 3 *bar_width, results_volume[5], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='pink',\n",
    "                 label='Bagging Regressor')\n",
    "\n",
    "rects3 = plt.bar(index + 4 *bar_width, results_volume[0], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='y',\n",
    "                 label='Decision Tree Regression')\n",
    "\n",
    "rects4 = plt.bar(index + 5 *bar_width, results_volume[4], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='black',\n",
    "                 label='KNN')\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('Algorithms Comparison Volume')\n",
    "plt.xticks(index + bar_width *2, ())\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Plot for Travel time\n",
    "n_groups = 1\n",
    "\n",
    " \n",
    "# create plot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rcParams['figure.figsize'] = 12,10\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.2\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, results_travel[1], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Random Forest')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, results_travel[2], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='Bayesian Regression ')\n",
    "\n",
    "rects3 = plt.bar(index + 2 *bar_width, results_travel[3], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='SVR')\n",
    "\n",
    "rects3 = plt.bar(index + 3 *bar_width, results_travel[0], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='y',\n",
    "                 label='Decision Tree Regression')\n",
    "\n",
    "rects4 = plt.bar(index + 4 *bar_width, results_travel[4], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='black',\n",
    "                 label='KNN')\n",
    "\n",
    "rects5 = plt.bar(index + 5 *bar_width, results_travel[5], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='pink',\n",
    "                 label='Bagging Regressor')\n",
    "\n",
    " \n",
    " \n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('Algorithms Comparison Travel time')\n",
    "plt.xticks(index + bar_width *2, ())\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
